{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6521, 11)\n",
      "Size before: (450668, 13)\n",
      "Size after: (72458, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "movie_metadata = pd.read_csv('MovieSummaries/movie.metadata.tsv',sep='\\t')\n",
    "\n",
    "movie_metadata.columns = ['1. Wikipedia movie ID',\n",
    "                          '2. Freebase movie ID',\n",
    "                          '3. Movie name',\n",
    "                          '4. Movie release date',\n",
    "                          '5. Movie box office revenue',\n",
    "                          '6. Movie runtime',\n",
    "                          '7. Movie languages (Freebase ID:name tuples)',\n",
    "                          '8. Movie countries (Freebase ID:name tuples)',\n",
    "                          '9. Movie genres (Freebase ID:name tuples)']\n",
    "\n",
    "character_metadata = pd.read_csv('MovieSummaries/character.metadata.tsv',sep='\\t')\n",
    "\n",
    "character_metadata.columns = ['1. Wikipedia movie ID',\n",
    "                              '2. Freebase movie ID',\n",
    "                              '3. Movie release date',\n",
    "                              '4. Character name',\n",
    "                              '5. Actor date of birth',\n",
    "                              '6. Actor gender',\n",
    "                              '7. Actor height (in meters)',\n",
    "                              '8. Actor ethnicity (Freebase ID)',\n",
    "                              '9. Actor name',\n",
    "                              '10. Actor age at movie release',\n",
    "                              '11. Freebase character/actor map ID',\n",
    "                              '12. Freebase character ID',\n",
    "                              '13. Freebase actor ID']\n",
    "\n",
    "movie_metadata_bechdel = pd.read_csv(\"CMU_bechdel_added.csv\")\n",
    "print(movie_metadata_bechdel.shape)\n",
    "movie_metadata_bechdel = movie_metadata_bechdel.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "\n",
    "character_metadata_bechdel = character_metadata.copy(deep = True)\n",
    "print(\"Size before:\", character_metadata_bechdel.shape)\n",
    "character_metadata_bechdel = character_metadata_bechdel[character_metadata_bechdel['2. Freebase movie ID'].isin(movie_metadata_bechdel[\"2. Freebase movie ID\"].to_numpy())]\n",
    "print(\"Size after:\", character_metadata_bechdel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6521, 10)\n",
      "(6202, 10)\n"
     ]
    }
   ],
   "source": [
    "print(movie_metadata_bechdel.shape)\n",
    "movie_metadata_bechdel = movie_metadata_bechdel[movie_metadata_bechdel['2. Freebase movie ID'].isin(character_metadata_bechdel[\"2. Freebase movie ID\"].to_numpy())]\n",
    "print(movie_metadata_bechdel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42303, 2)\n",
      "(5194, 2)\n"
     ]
    }
   ],
   "source": [
    "plot_summaries=pd.read_csv('MovieSummaries/plot_summaries.txt', sep='\\t', header=None, names=['id', 'plot_summary'])\n",
    "plot_summaries_bechdel = plot_summaries[plot_summaries['id'].isin(character_metadata_bechdel['1. Wikipedia movie ID'].to_numpy())]\n",
    "\n",
    "plot_summaries.head()\n",
    "print(plot_summaries.shape)\n",
    "print(plot_summaries_bechdel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/42303 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Shlykov', 'a', 'hard', 'working', 'taxi', 'driver', 'and', 'Lyosha', 'a', 'saxophonist', 'develop', 'a', 'bizarre', 'love', 'hate', 'relationship', 'and', 'despite', 'their', 'prejudices', 'realize', 'they', 'aren', 't', 'so', 'different', 'after', 'all']\n",
      "['shlykov', 'a', 'hard', 'working', 'taxi', 'driver', 'and', 'lyosha', 'a', 'saxophonist', 'develop', 'a', 'bizarre', 'love', 'hate', 'relationship', 'and', 'despite', 'their', 'prejudices', 'realize', 'they', 'aren', 't', 'so', 'different', 'after', 'all']\n",
      "[['shlykov', 'a', 'hard', 'working', 'taxi', 'driver', 'and', 'lyosha', 'a', 'saxophonist', 'develop', 'a', 'bizarre', 'love', 'hate', 'relationship', 'and', 'despite', 'their', 'prejudices', 'realize', 'they', 'aren', 't', 'so', 'different', 'after', 'all']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/42303 [02:20<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-937999aeab29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtokens_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             )\n\u001b[1;32m--> 860\u001b[1;33m         return self._input_request(str(prompt),\n\u001b[0m\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from tqdm import tqdm\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens_list=[]\n",
    "for i, row in tqdm(plot_summaries.iterrows(), total=plot_summaries.shape[0]):\n",
    "    tokens = tokenizer.tokenize(row[1])\n",
    "    print(tokens)\n",
    "    tokens = [x.lower() for x in tokens]\n",
    "    print(tokens)\n",
    "    tokens_list.append(tokens)\n",
    "    print(tokens_list)\n",
    "    input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-year-old Will Hunting  of South Boston has a genius-level intellect but chooses to work as a janitor at the Massachusetts Institute of Technology and spend his free time with his friends Chuckie Sullivan , Billy McBride  and Morgan O'Mally . When Fields Medal-winning combinatorialist Professor Gerald Lambeau  posts a difficult problem taken from algebraic graph theory as a challenge for his graduate students to solve, Will solves the problem quickly but anonymously. Lambeau posts a much more difficult problem and chances upon Will solving it, but Will runs off. Will meets Skylar , a British student about to graduate from Harvard University and pursue a graduate degree at Stanford University School of Medicine in California. Will is faced with incarceration after assaulting a man who had bullied him as a child. Lambeau arranges for Will to forgo jail time if he agrees to study mathematics under Lambeau's supervision and to see a therapist. Will agrees, but treats his first few therapists with contempt and they refuse to work with him. In desperation, Lambeau calls on Sean Maguire , his estranged college roommate who also grew up in South Boston and now teaches psychology at Bunker Hill Community College. Unlike the other therapists, Sean pushes back at Will and overcomes his defense mechanisms, and after a few unproductive sessions Will begins to open up. Will is particularly struck by Sean's story of how he met his wife by giving up his ticket to the historic sixth game of the 1975 World Series after falling in love at first sight. Sean doesn't regret his decision, nor does he regret the final years of his marriage when his wife was dying of cancer. This encourages Will to build a relationship with Skylar, though he lies to her about his past and is reluctant to introduce her to his friends or show her his run-down neighborhood. Will also challenges Sean to take an objective look at his own life, since Sean has been unable to move on from his wife's death. Will begins to chafe under Lambeau's high expectations and makes a mockery of job interviews that Lambeau arranges for him. Sean cautions Lambeau against pushing the boy too hard. Will walks in on a heated argument between the two over his future and it greatly upsets him. When Skylar asks Will to move to California with her, he panics and pushes her away, revealing that he is an orphan and that his foster father physically abused him. Skylar tells Will that she loves him, but he denies loving her and then leaves her. He next storms out on Lambeau, dismissing the mathematical research he has been doing. Sean points out that Will is so adept at anticipating future failure in his interpersonal relationships that he deliberately sabotages them in order to avoid the risk of emotional pain. When Will refuses to give an honest reply about what he wants to do with his life, Sean shows him the door. Will tells Chuckie he wants to be a laborer for the rest of his life; Chuckie responds that it would be an insult to his friends for Will to waste his potential, and that his fondest wish is that Will should leave to pursue something greater. Will decides to accept one of the job offers arranged by Lambeau. At another therapy session, Sean and Will share that they were both victims of child abuse, and Sean helps Will to accept that the abuse he suffered wasn't his fault. Having helped Will overcome his problems, Sean reconciles with Lambeau and decides to take a sabbatical to travel the world. When Will's friends present him with a rebuilt Chevrolet Nova for his 21st birthday, he decides to pass on his lucrative job offers and drive to California to reunite with Skylar.\n",
      "['20', 'year', 'old', 'will', 'hunting', 'of', 'south', 'boston', 'has', 'a', 'genius', 'level', 'intellect', 'but', 'chooses', 'to', 'work', 'as', 'a', 'janitor', 'at', 'the', 'massachusetts', 'institute', 'of', 'technology', 'and', 'spend', 'his', 'free', 'time', 'with', 'his', 'friends', 'chuckie', 'sullivan', 'billy', 'mcbride', 'and', 'morgan', 'o', 'mally', 'when', 'fields', 'medal', 'winning', 'combinatorialist', 'professor', 'gerald', 'lambeau', 'posts', 'a', 'difficult', 'problem', 'taken', 'from', 'algebraic', 'graph', 'theory', 'as', 'a', 'challenge', 'for', 'his', 'graduate', 'students', 'to', 'solve', 'will', 'solves', 'the', 'problem', 'quickly', 'but', 'anonymously', 'lambeau', 'posts', 'a', 'much', 'more', 'difficult', 'problem', 'and', 'chances', 'upon', 'will', 'solving', 'it', 'but', 'will', 'runs', 'off', 'will', 'meets', 'skylar', 'a', 'british', 'student', 'about', 'to', 'graduate', 'from', 'harvard', 'university', 'and', 'pursue', 'a', 'graduate', 'degree', 'at', 'stanford', 'university', 'school', 'of', 'medicine', 'in', 'california', 'will', 'is', 'faced', 'with', 'incarceration', 'after', 'assaulting', 'a', 'man', 'who', 'had', 'bullied', 'him', 'as', 'a', 'child', 'lambeau', 'arranges', 'for', 'will', 'to', 'forgo', 'jail', 'time', 'if', 'he', 'agrees', 'to', 'study', 'mathematics', 'under', 'lambeau', 's', 'supervision', 'and', 'to', 'see', 'a', 'therapist', 'will', 'agrees', 'but', 'treats', 'his', 'first', 'few', 'therapists', 'with', 'contempt', 'and', 'they', 'refuse', 'to', 'work', 'with', 'him', 'in', 'desperation', 'lambeau', 'calls', 'on', 'sean', 'maguire', 'his', 'estranged', 'college', 'roommate', 'who', 'also', 'grew', 'up', 'in', 'south', 'boston', 'and', 'now', 'teaches', 'psychology', 'at', 'bunker', 'hill', 'community', 'college', 'unlike', 'the', 'other', 'therapists', 'sean', 'pushes', 'back', 'at', 'will', 'and', 'overcomes', 'his', 'defense', 'mechanisms', 'and', 'after', 'a', 'few', 'unproductive', 'sessions', 'will', 'begins', 'to', 'open', 'up', 'will', 'is', 'particularly', 'struck', 'by', 'sean', 's', 'story', 'of', 'how', 'he', 'met', 'his', 'wife', 'by', 'giving', 'up', 'his', 'ticket', 'to', 'the', 'historic', 'sixth', 'game', 'of', 'the', '1975', 'world', 'series', 'after', 'falling', 'in', 'love', 'at', 'first', 'sight', 'sean', 'doesn', 't', 'regret', 'his', 'decision', 'nor', 'does', 'he', 'regret', 'the', 'final', 'years', 'of', 'his', 'marriage', 'when', 'his', 'wife', 'was', 'dying', 'of', 'cancer', 'this', 'encourages', 'will', 'to', 'build', 'a', 'relationship', 'with', 'skylar', 'though', 'he', 'lies', 'to', 'her', 'about', 'his', 'past', 'and', 'is', 'reluctant', 'to', 'introduce', 'her', 'to', 'his', 'friends', 'or', 'show', 'her', 'his', 'run', 'down', 'neighborhood', 'will', 'also', 'challenges', 'sean', 'to', 'take', 'an', 'objective', 'look', 'at', 'his', 'own', 'life', 'since', 'sean', 'has', 'been', 'unable', 'to', 'move', 'on', 'from', 'his', 'wife', 's', 'death', 'will', 'begins', 'to', 'chafe', 'under', 'lambeau', 's', 'high', 'expectations', 'and', 'makes', 'a', 'mockery', 'of', 'job', 'interviews', 'that', 'lambeau', 'arranges', 'for', 'him', 'sean', 'cautions', 'lambeau', 'against', 'pushing', 'the', 'boy', 'too', 'hard', 'will', 'walks', 'in', 'on', 'a', 'heated', 'argument', 'between', 'the', 'two', 'over', 'his', 'future', 'and', 'it', 'greatly', 'upsets', 'him', 'when', 'skylar', 'asks', 'will', 'to', 'move', 'to', 'california', 'with', 'her', 'he', 'panics', 'and', 'pushes', 'her', 'away', 'revealing', 'that', 'he', 'is', 'an', 'orphan', 'and', 'that', 'his', 'foster', 'father', 'physically', 'abused', 'him', 'skylar', 'tells', 'will', 'that', 'she', 'loves', 'him', 'but', 'he', 'denies', 'loving', 'her', 'and', 'then', 'leaves', 'her', 'he', 'next', 'storms', 'out', 'on', 'lambeau', 'dismissing', 'the', 'mathematical', 'research', 'he', 'has', 'been', 'doing', 'sean', 'points', 'out', 'that', 'will', 'is', 'so', 'adept', 'at', 'anticipating', 'future', 'failure', 'in', 'his', 'interpersonal', 'relationships', 'that', 'he', 'deliberately', 'sabotages', 'them', 'in', 'order', 'to', 'avoid', 'the', 'risk', 'of', 'emotional', 'pain', 'when', 'will', 'refuses', 'to', 'give', 'an', 'honest', 'reply', 'about', 'what', 'he', 'wants', 'to', 'do', 'with', 'his', 'life', 'sean', 'shows', 'him', 'the', 'door', 'will', 'tells', 'chuckie', 'he', 'wants', 'to', 'be', 'a', 'laborer', 'for', 'the', 'rest', 'of', 'his', 'life', 'chuckie', 'responds', 'that', 'it', 'would', 'be', 'an', 'insult', 'to', 'his', 'friends', 'for', 'will', 'to', 'waste', 'his', 'potential', 'and', 'that', 'his', 'fondest', 'wish', 'is', 'that', 'will', 'should', 'leave', 'to', 'pursue', 'something', 'greater', 'will', 'decides', 'to', 'accept', 'one', 'of', 'the', 'job', 'offers', 'arranged', 'by', 'lambeau', 'at', 'another', 'therapy', 'session', 'sean', 'and', 'will', 'share', 'that', 'they', 'were', 'both', 'victims', 'of', 'child', 'abuse', 'and', 'sean', 'helps', 'will', 'to', 'accept', 'that', 'the', 'abuse', 'he', 'suffered', 'wasn', 't', 'his', 'fault', 'having', 'helped', 'will', 'overcome', 'his', 'problems', 'sean', 'reconciles', 'with', 'lambeau', 'and', 'decides', 'to', 'take', 'a', 'sabbatical', 'to', 'travel', 'the', 'world', 'when', 'will', 's', 'friends', 'present', 'him', 'with', 'a', 'rebuilt', 'chevrolet', 'nova', 'for', 'his', '21st', 'birthday', 'he', 'decides', 'to', 'pass', 'on', 'his', 'lucrative', 'job', 'offers', 'and', 'drive', 'to', 'california', 'to', 'reunite', 'with', 'skylar']\n",
      "to         32\n",
      "his        28\n",
      "will       27\n",
      "and        20\n",
      "a          17\n",
      "           ..\n",
      "story       1\n",
      "how         1\n",
      "met         1\n",
      "giving      1\n",
      "reunite     1\n",
      "Name: count, Length: 318, dtype: int64\n",
      "          4. Character name 6. Actor gender\n",
      "90821          Henry Lipkin               M\n",
      "90822          Sean Maguire               M\n",
      "90823          Will Hunting               M\n",
      "90824      Chuckie Sullivan               M\n",
      "90825  Prof. Gerald Lambeau               M\n",
      "90826                Skylar               F\n",
      "90827        Morgan O'Mally               M\n",
      "90828         Billy McBride               M\n",
      "90829                   Tom               M\n",
      "90830                 Cathy               F\n",
      "90831               Krystyn               F\n",
      "90832                 Jerve               M\n"
     ]
    }
   ],
   "source": [
    "movie_idx = 255\n",
    "sample_text = plot_summaries_bechdel.iloc[movie_idx][\"plot_summary\"]\n",
    "print(sample_text)\n",
    "tokens = tokenizer.tokenize(sample_text)\n",
    "tokens = [x.lower() for x in tokens]\n",
    "tokens_freq = pd.Series(tokens).value_counts(sort=True)\n",
    "print(tokens)\n",
    "print(tokens_freq)\n",
    "first_movie_id = plot_summaries_bechdel.iloc[movie_idx][\"id\"]\n",
    "character_list = character_metadata_bechdel[character_metadata_bechdel['1. Wikipedia movie ID'] == first_movie_id][['4. Character name','6. Actor gender']]\n",
    "print(character_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   character_name gender  no_mention\n",
      "2            sean      M          12\n",
      "3         maguire      M           1\n",
      "4            will      M          27\n",
      "5         hunting      F           1\n",
      "6         chuckie      M           3\n",
      "7        sullivan      M           1\n",
      "10         skylar      F           5\n",
      "11         morgan      M           1\n",
      "13          billy      M           1\n",
      "14        mcbride      M           1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-191-482cfb0eb104>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  character_mention_freq[\"no_mention\"] = tokens_intersection.values#pd.DataFrame({'4. Character name':character_mention_freq[0], 'no_mention':character_mention_freq.values})\n"
     ]
    }
   ],
   "source": [
    "character_list_processed = character_list.copy()\n",
    "character_list_processed = character_list_processed.dropna()\n",
    "#Lowercase character names\n",
    "character_list_processed[\"4. Character name\"] = character_list_processed[\"4. Character name\"].str.lower()\n",
    "\n",
    "#Split name and surname to two columns\n",
    "character_list_processed[[\"4. Character name\", \"4.5. Character surname\"]] = character_list_processed[\"4. Character name\"].str.split(' ', n=1, expand=True)\n",
    "\n",
    "#Stack two columns as rows as if surnames are different characters\n",
    "character_list_stacked = character_list_processed[[\"4. Character name\", \"4.5. Character surname\"]].stack()\n",
    "\n",
    "#Duplicate and stack gender column so that dataframe matches\n",
    "character_gender_stacked = pd.concat([character_list_processed[\"6. Actor gender\"],character_list_processed[\"6. Actor gender\"]])\n",
    "character_gender_stacked = pd.concat([pd.Series(character_list_stacked.to_numpy()), pd.Series(character_gender_stacked.to_numpy())], axis = 1)\n",
    "character_gender_stacked_idx = character_gender_stacked.set_index(0)\n",
    "#print(character_gender_stacked)\n",
    "#print(tokens_freq)\n",
    "#print(character_gender_stacked)\n",
    "#print(tokens_freq.index)\n",
    "#print(character_gender_stacked_idx.index.intersection(tokens_freq.index))\n",
    "#print(tokens_freq[character_gender_stacked_idx.index.intersection(tokens_freq.index)])\n",
    "tokens_intersection = tokens_freq[character_gender_stacked_idx.index.intersection(tokens_freq.index)]\n",
    "#Get the intersection between the tokens and characters dataframe\n",
    "character_mention_freq = character_gender_stacked[character_gender_stacked[0].isin(character_gender_stacked_idx.index.intersection(tokens_freq.index))]\n",
    "\n",
    "character_mention_freq[\"no_mention\"] = tokens_intersection.values#pd.DataFrame({'4. Character name':character_mention_freq[0], 'no_mention':character_mention_freq.values})\n",
    "character_mention_freq.columns = [\"character_name\", \"gender\", \"no_mention\"]\n",
    "character_list_final = character_mention_freq\n",
    "print(character_list_final)\n",
    "\n",
    "#character_list1 = character_list[character_list[\"4. Character name\"].isin(tokens_freq.index.intersection(character_list[\"4. Character name\"]).to_numpy())]\n",
    "#print(character_list1.sort_values(by=[\"4. Character name\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11320754716981132\n"
     ]
    }
   ],
   "source": [
    "#print(character_list)\n",
    "#character_list_freq_added = pd.merge(character_list, character_mention_freq, on=\"4. Character name\", how=\"left\")\n",
    "#print(character_list_freq_added)\n",
    "\n",
    "character_list_freq_added = character_list_final.groupby(['gender']).sum() \n",
    "if character_list_freq_added['no_mention'].shape[0] == 2:\n",
    "    female_mention, male_mention = character_list_freq_added['no_mention'][0], character_list_freq_added['no_mention'][1] #groupby is alphabethic, index 0 = F\n",
    "    mention_ratio = female_mention/(female_mention + male_mention)\n",
    "elif character_list_freq_added['no_mention'].index[0] == \"M\":\n",
    "    mention_ratio = 0.\n",
    "elif character_list_freq_added['no_mention'].index[0] == \"F\":\n",
    "    mention_ratio = 1.\n",
    "else:\n",
    "    mention_ratio = np.nan\n",
    "    \n",
    "print(mention_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
